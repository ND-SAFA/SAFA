{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.creators.trace_dataset_creator import TraceDatasetCreator\n",
    "from data.creators.multi_trace_dataset_creator import MultiTraceDatasetCreator\n",
    "from data.datasets.trace_dataset import TraceDataset\n",
    "from data.readers.hub_project_reader import HubProjectReader\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from util.logging.logger_manager import LoggerManager, logger\n",
    "from util.logging.logger_config import LoggerConfig\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TGenLogger tgen (INFO)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.expanduser(\"~/desktop/safa/logs\")\n",
    "LoggerManager.configure_logger(LoggerConfig(output_dir=log_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix_from_term_frequencies(tf_source, tf_target):\n",
    "    \"\"\"\n",
    "    Calculates the similarity matrix used for predicting traces from the term frequencies of the sources and targets\n",
    "    :param tf_source: The term frequencies of the sources\n",
    "    :param tf_target: The term frequencies of the targets\n",
    "    :return: The similarity matrix where each cell contains the similarity of the corresponding source (row) and target (col)\n",
    "    \"\"\"\n",
    "    return 1 - pairwise_distances(tf_source, Y=tf_target, metric=\"cosine\", n_jobs=-1)\n",
    "\n",
    "def create_term_frequency_matrices(model, raw_sources: pd.Series, raw_targets: pd.Series):\n",
    "    \"\"\"\n",
    "    Creates 2 TermFrequencyMatrices (one for A another for B) where the weight of\n",
    "    each (row, col) pair is calculated via TF-IDF\n",
    "    :param raw_sources : The source documents whose matrix is the first element\n",
    "    :param raw_targets : The target documents whose matrix is the second element\n",
    "    :return: CountMatrix for raw_sources and raw_targets, and also the trained model\n",
    "    \"\"\"\n",
    "    set_source: csr_matrix = model.transform(raw_sources)\n",
    "    set_target: csr_matrix = model.transform(raw_targets)\n",
    "    return set_source, set_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/cm1.zip\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4719a95a7911878e5dd403ca7f5b5600d50ea6eb74744ceb527265f0637985ad/CM1/CM1-sourceArtifacts.xml:22\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4719a95a7911878e5dd403ca7f5b5600d50ea6eb74744ceb527265f0637985ad/CM1/CM1-targetArtifacts.xml:53\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4719a95a7911878e5dd403ca7f5b5600d50ea6eb74744ceb527265f0637985ad/CM1/CM1-answerSet.xml:45\n",
      "Artifacts: 75 Traces: 45 Queries: 1\n",
      "Number of orphan artifacts (26)\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|████████████████| 75/75 [00:00<00:00, 927943.36it/s]\n",
      "Generating negative links between High Level Requirements -> Low Level Requireme"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[High Level Requirements: 22],[Low Level Requirements: 53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace dataset(+45, -(1121) = 1166)\n",
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/drone.zip\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/30e2f908ec8ca05678e1daf3aab6d65f5b26e4424fc3af099482cba26f2fcdc6/drone_tasks/base/Code.csv:458\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/30e2f908ec8ca05678e1daf3aab6d65f5b26e4424fc3af099482cba26f2fcdc6/drone_tasks/base/Design Definitions.csv:99\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/30e2f908ec8ca05678e1daf3aab6d65f5b26e4424fc3af099482cba26f2fcdc6/drone_tasks/base/Requirements.csv:55\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/30e2f908ec8ca05678e1daf3aab6d65f5b26e4424fc3af099482cba26f2fcdc6/drone_tasks/base/Requirements2Design Definitions.csv:58\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/30e2f908ec8ca05678e1daf3aab6d65f5b26e4424fc3af099482cba26f2fcdc6/drone_tasks/base/Design Definitions2Code.csv:222\n",
      "Artifacts: 612 Traces: 280 Queries: 2\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|█████████████| 612/612 [00:00<00:00, 2234041.82it/s]\n",
      "Generating negative links between Requirements -> Design Definitions: 100%|█| 55\n",
      "Generating negative links between Design Definitions -> Code: 100%|█| 99/99 [00:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Code: 458],[Design Definitions: 99],[Requirements: 55]\n",
      "Trace dataset(+280, -(50507) = 50787)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertorodriguez/Projects/SAFA/tgen/src/scripts/../data/dataframes/abstract_project_dataframe.py:136: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  data1 = dataframe1.to_dict(orient=orient)\n",
      "/Users/albertorodriguez/Projects/SAFA/tgen/src/scripts/../data/dataframes/abstract_project_dataframe.py:137: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  data2 = dataframe2.to_dict(orient=orient)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/traincontroller.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a091b70af3ca44bfb729a3ef7bc03dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/b7d23709b95609c6d8f17529bb93ae67f92b248a0826edd4a00db0104d900df7/TrainController/Originals/Source_1/SRS.csv:219\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/b7d23709b95609c6d8f17529bb93ae67f92b248a0826edd4a00db0104d900df7/TrainController/Originals/Source_1/SDD.csv:534\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/b7d23709b95609c6d8f17529bb93ae67f92b248a0826edd4a00db0104d900df7/TrainController/Originals/Source_1/SSRS.csv:583\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/b7d23709b95609c6d8f17529bb93ae67f92b248a0826edd4a00db0104d900df7/TrainController/Originals/Source_1/SDD2SRS.txt:581\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/b7d23709b95609c6d8f17529bb93ae67f92b248a0826edd4a00db0104d900df7/TrainController/Originals/Source_1/SSRS2SDD.txt:700\n",
      "Artifacts: 1336 Traces: 1280 Queries: 2\n",
      "Number of orphan artifacts (150)\n",
      "No missing source artifacts. (1)\n",
      "No missing target artifacts. (12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|███████████| 1336/1336 [00:00<00:00, 1461933.25it/s]\n",
      "Generating negative links between SDD -> SRS: 100%|█| 534/534 [00:41<00:00, 12.7\n",
      "Generating negative links between SSRS -> SDD: 100%|█| 583/583 [01:48<00:00,  5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Srs: 219],[Sdd: 534],[Ssrs: 583]\n",
      "Trace dataset(+1259, -(427009) = 428268)\n",
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/itrust.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2933bdae9fbd4d49b35c43138f724f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/32a72197dd693cf25ecbc63b850ba3e68df3151db71f040a488b7ed73b847b8c/itrust_tasks/base/Use Cases.csv:131\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/32a72197dd693cf25ecbc63b850ba3e68df3151db71f040a488b7ed73b847b8c/itrust_tasks/base/JSP Code.csv:165\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/32a72197dd693cf25ecbc63b850ba3e68df3151db71f040a488b7ed73b847b8c/itrust_tasks/base/Java Code.csv:226\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/32a72197dd693cf25ecbc63b850ba3e68df3151db71f040a488b7ed73b847b8c/itrust_tasks/base/Use Cases2Java Code.csv:286\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/32a72197dd693cf25ecbc63b850ba3e68df3151db71f040a488b7ed73b847b8c/itrust_tasks/base/Use Cases2JSP Code.csv:113\n",
      "Artifacts: 522 Traces: 399 Queries: 2\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|█████████████| 522/522 [00:00<00:00, 1897250.16it/s]\n",
      "Generating negative links between Use Cases -> Java Code: 100%|█| 131/131 [00:10\n",
      "Generating negative links between Use Cases -> JSP Code: 100%|█| 131/131 [00:07<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Use Cases: 131],[Jsp Code: 165],[Java Code: 226]\n",
      "Trace dataset(+399, -(50822) = 51221)\n",
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/mip.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4bbdd5aab242ecbcb40d57bda5700e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/100k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4129319c0de134940aa6e16baa1bb36832b3782a54ecaa7bf1ebb836d33cc03f/mip/clean/components.csv:21\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4129319c0de134940aa6e16baa1bb36832b3782a54ecaa7bf1ebb836d33cc03f/mip/clean/requirements.csv:126\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/4129319c0de134940aa6e16baa1bb36832b3782a54ecaa7bf1ebb836d33cc03f/mip/AnswerMatrix.csv:132\n",
      "Artifacts: 147 Traces: 132 Queries: 1\n",
      "Number of orphan artifacts (22)\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|█████████████| 147/147 [00:00<00:00, 1529932.23it/s]\n",
      "Generating negative links between Requirements -> Components: 100%|█| 126/126 [0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Components: 21],[Requirements: 126]\n",
      "Trace dataset(+132, -(2646) = 2778)\n",
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/cchit.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453c579373e94b699e460697fbae6826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/161k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/source.xml:118\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/target.xml:1066\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/answer.txt:587\n",
      "Artifacts: 1180 Traces: 587 Queries: 1\n",
      "Number of orphan artifacts (693)\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|███████████| 1180/1180 [00:00<00:00, 2259944.62it/s]\n",
      "Generating negative links between Requirements -> Regulatory Codes: 100%|█| 116/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Requirements: 116],[Regulatory Codes: 1064]\n",
      "Trace dataset(+587, -(122837) = 123424)\n",
      "657644\n"
     ]
    }
   ],
   "source": [
    "project_readers = [HubProjectReader(\"cm1\"), HubProjectReader(\"drone\"), HubProjectReader(\"traincontroller\"),\n",
    "                  HubProjectReader(\"itrust\"), HubProjectReader(\"mip\"), HubProjectReader(\"cchit\")]\n",
    "dataset_creator = MultiTraceDatasetCreator(project_readers)\n",
    "dataset = dataset_creator.create()\n",
    "trace_df = dataset.to_dataframe()\n",
    "print(len(trace_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df.to_csv(os.path.expanduser(\"~/desktop/safa/datasets/openai/all.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TfidfVectorizer()\n",
    "sources = list(set(trace_df[\"source\"]))\n",
    "targets = list(set(trace_df[\"target\"]))\n",
    "artifacts = sources + targets\n",
    "print(len(artifacts))\n",
    "model.fit(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hardness_label(hardness):\n",
    "    if hardness < 0.3:\n",
    "        return \"easy\"\n",
    "    if hardness < 0.66:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wx/rxzz6khs4w7bq1sthds7lr280000gn/T/ipykernel_14966/3191652503.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ms_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_term_frequency_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_similarity_matrix_from_term_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msim_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mhardness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msim_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wx/rxzz6khs4w7bq1sthds7lr280000gn/T/ipykernel_14966/1420853604.py\u001b[0m in \u001b[0;36mcalculate_similarity_matrix_from_term_frequencies\u001b[0;34m(tf_source, tf_target)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0meach\u001b[0m \u001b[0mcell\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_term_frequency_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_sources\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_targets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_dist_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m     Parallel(backend=\"threading\", n_jobs=n_jobs)(\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         return self._get_pool().apply_async(\n\u001b[0m\u001b[1;32m    253\u001b[0m             SafeFunction(func), callback=callback)\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m_get_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \"\"\"\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0mPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_queues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return self._repopulate_pool_static(self._ctx, self.Process,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inqueue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/dummy/__init__.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_children'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0m_limbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0m_start_new_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_active_limbo_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "hardnesses = []\n",
    "hardness_labels = []\n",
    "for i, row in trace_df.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    target = row[\"target\"]\n",
    "    label = row[\"label\"]\n",
    "    \n",
    "    s_matrix, t_matrix = create_term_frequency_matrices(model, [source], [target])\n",
    "    sim_matrix = calculate_similarity_matrix_from_term_frequencies(s_matrix, t_matrix)\n",
    "    sim_score = sim_matrix[0][0]\n",
    "    hardness = abs(label - sim_score)\n",
    "    hardness_label = get_hardness_label(hardness)\n",
    "    \n",
    "    scores.append(sim_score)\n",
    "    hardnesses.append(hardness)\n",
    "    hardness_labels.append(hardness_label)\n",
    "trace_df[\"similarity\"] = scores\n",
    "trace_df[\"hardness\"] = hardnesses\n",
    "trace_df[\"hardness_label\"] = hardness_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBU.SSRS.1059</td>\n",
       "      <td>The OBU shall take a configurable brake build-...</td>\n",
       "      <td>PTC.SDD.2915</td>\n",
       "      <td>The OBU calculates the permitted speed from a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1715</td>\n",
       "      <td>The system shall include the ability to print ...</td>\n",
       "      <td>262</td>\n",
       "      <td>The system shall provide the ability to receiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OBU.SSRS.627</td>\n",
       "      <td>The OBU software shall be developed to use an ...</td>\n",
       "      <td>PTC.SDD.1052</td>\n",
       "      <td>The TG-PTC system shall abstract hardware from...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC31S1</td>\n",
       "      <td>The expired prescription report list is titled...</td>\n",
       "      <td>ViewExpiredPrescriptionsAction</td>\n",
       "      <td>package edu.ncsu.csc.itrust.action; import jav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1714</td>\n",
       "      <td>The system shall include Standard Laboratory a...</td>\n",
       "      <td>565</td>\n",
       "      <td>The system shall relate medication allergies t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source_id                                             source  \\\n",
       "0  OBU.SSRS.1059  The OBU shall take a configurable brake build-...   \n",
       "1           1715  The system shall include the ability to print ...   \n",
       "2   OBU.SSRS.627  The OBU software shall be developed to use an ...   \n",
       "3         UC31S1  The expired prescription report list is titled...   \n",
       "4           1714  The system shall include Standard Laboratory a...   \n",
       "\n",
       "                        target_id  \\\n",
       "0                    PTC.SDD.2915   \n",
       "1                             262   \n",
       "2                    PTC.SDD.1052   \n",
       "3  ViewExpiredPrescriptionsAction   \n",
       "4                             565   \n",
       "\n",
       "                                              target  label  \n",
       "0  The OBU calculates the permitted speed from a ...      1  \n",
       "1  The system shall provide the ability to receiv...      1  \n",
       "2  The TG-PTC system shall abstract hardware from...      1  \n",
       "3  package edu.ncsu.csc.itrust.action; import jav...      1  \n",
       "4  The system shall relate medication allergies t...      1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(trace_df))\n",
    "trace_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 100\n",
    "hardness_lower = 0\n",
    "hardness_upper = 0.9\n",
    "strat = \"sample\"\n",
    "\n",
    "selection_strats = {\n",
    "    \"top\": lambda df: df[:n_top],\n",
    "    \"sample\": lambda df: df.sample(n=n_top)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>source</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>OBU.SSRS.1595</td>\n",
       "      <td>The OBU shall handle train crew acknowledment ...</td>\n",
       "      <td>PTC.SDD.4104</td>\n",
       "      <td>Transitioning between PTC territory and Non-PT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>DD-213</td>\n",
       "      <td>Log all GCS related events All commands sent t...</td>\n",
       "      <td>ReadDispatcher.java</td>\n",
       "      <td>package edu.nd.dronology.gstation.connector.di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>OBU.SSRS.1957</td>\n",
       "      <td>The OBU shall be able to load an ITCSM Agent s...</td>\n",
       "      <td>PTC.SDD.7415</td>\n",
       "      <td>Each TG-PTC subsystem shall adhere to the agen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>PTC.SDD.6661</td>\n",
       "      <td>Centralized Logging is the ability of the syst...</td>\n",
       "      <td>PTC.SRS.226</td>\n",
       "      <td>6.6.2 Centralized Logging (REQ1185) The TG-PTC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>OBU.SSRS.717</td>\n",
       "      <td>The OBU shall react to any user request in a m...</td>\n",
       "      <td>PTC.SDD.7200</td>\n",
       "      <td>The TG-PTC system shall always keep users info...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          source_id                                             source  \\\n",
       "102   OBU.SSRS.1595  The OBU shall handle train crew acknowledment ...   \n",
       "1024         DD-213  Log all GCS related events All commands sent t...   \n",
       "284   OBU.SSRS.1957  The OBU shall be able to load an ITCSM Agent s...   \n",
       "803    PTC.SDD.6661  Centralized Logging is the ability of the syst...   \n",
       "531    OBU.SSRS.717  The OBU shall react to any user request in a m...   \n",
       "\n",
       "                target_id                                             target  \\\n",
       "102          PTC.SDD.4104  Transitioning between PTC territory and Non-PT...   \n",
       "1024  ReadDispatcher.java  package edu.nd.dronology.gstation.connector.di...   \n",
       "284          PTC.SDD.7415  Each TG-PTC subsystem shall adhere to the agen...   \n",
       "803           PTC.SRS.226  6.6.2 Centralized Logging (REQ1185) The TG-PTC...   \n",
       "531          PTC.SDD.7200  The TG-PTC system shall always keep users info...   \n",
       "\n",
       "      label  \n",
       "102       1  \n",
       "1024      1  \n",
       "284       1  \n",
       "803       1  \n",
       "531       1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_from(df):\n",
    "    pos_df = df[df[\"label\"] == 1]\n",
    "    neg_df = df[df[\"label\"] == 0]\n",
    "\n",
    "    selection_strat = selection_strats[strat]\n",
    "    selected_df = pd.concat([selection_strat(pos_df), selection_strat(neg_df)])\n",
    "    return selected_df\n",
    "\n",
    "selected_df = select_from(trace_df)\n",
    "\n",
    "unselected_indices = set(range(len(trace_df))) - set(selected_df.index)\n",
    "unselected_df = trace_df.iloc[list(unselected_indices)]\n",
    "\n",
    "print(f\"Selected: {len(selected_df)}\")\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting: Train / Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(selected_df, test_size=0.5, stratify=selected_df[\"label\"])\n",
    "print(f\"Train: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: /Users/albertorodriguez/desktop/safa/datasets/openai/cm1/train.jsonl (100)\n",
      "Exported: /Users/albertorodriguez/desktop/safa/datasets/openai/cm1/val.jsonl (100)\n",
      "Exported: /Users/albertorodriguez/desktop/safa/datasets/openai/cm1/test.jsonl (657444)\n"
     ]
    }
   ],
   "source": [
    "query_format = \"1. {}\\n2. {}\\n\\n###\\n\\n\"\n",
    "export_dir = os.path.expanduser(\"~/desktop/safa/datasets/openai/cm1\")\n",
    "\n",
    "def export_as_formatted(df, stage_name, dir_path):\n",
    "    entries = []\n",
    "    queries = []\n",
    "    responses = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        row_query = query_format.format(row[\"source\"], row[\"target\"], row[\"label\"])\n",
    "        row_response = \" yes###\" if row[\"label\"] == 1 else \" no###\"\n",
    "        entries.append({\n",
    "            \"prompt\": row_query,\n",
    "            \"completion\": row_response\n",
    "        })\n",
    "\n",
    "    openai_df = pd.DataFrame(entries)\n",
    "    export_path = os.path.join(dir_path, f\"{stage_name}.jsonl\")\n",
    "    openai_df.to_json(export_path,orient='records', lines=True)\n",
    "    print(f\"Exported: {export_path} ({len(openai_df)})\")\n",
    "    \n",
    "export_as_formatted(train_df, \"train\", export_dir)\n",
    "export_as_formatted(val_df, \"val\", export_dir)\n",
    "export_as_formatted(unselected_df, \"test\", export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163\n"
     ]
    }
   ],
   "source": [
    "row = train_df.sample(n=1).iloc[0]\n",
    "print(len(row[\"source\"]) + len(row[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
