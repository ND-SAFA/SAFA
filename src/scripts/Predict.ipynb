{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5abef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from util.logging.logger_manager import LoggerManager, logger\n",
    "from util.logging.logger_config import LoggerConfig\n",
    "\n",
    "log_path = os.path.expanduser(\"~/desktop/safa/logs\")\n",
    "LoggerManager.configure_logger(LoggerConfig(output_dir=log_path))\n",
    "\n",
    "def get_score(probs):\n",
    "    probs = probs[0]\n",
    "    if \" no\" not in probs and \" yes\" in probs:\n",
    "        v0 = 0\n",
    "        v1 = 1\n",
    "    else:\n",
    "        v0 = probs[\" no\"]\n",
    "        v1 = probs[\" yes\"]   \n",
    "    prob_v = [v0, v1]\n",
    "    score = softmax(prob_v)[1]\n",
    "    return score\n",
    "\n",
    "def calculate_metrics(labels, scores, threshold):\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    from sklearn.metrics import fbeta_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from train.metrics.precision_at_recall_metric import PrecisionAtRecallMetric\n",
    "    from train.metrics.f1_metric import FMetric\n",
    "    \n",
    "    f_metric = FMetric()\n",
    "    p_at_r = PrecisionAtRecallMetric()\n",
    "    pred_labels = list(map(lambda s: 1 if s >= threshold else 0, scores))\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"sklearn\": {\n",
    "            \"ap\": average_precision_score(labels, scores),\n",
    "        },\n",
    "        \"tgen\": {\n",
    "            **p_at_r._compute(scores, labels),\n",
    "            **f_metric._compute(scores, labels)\n",
    "        }\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def create_summary(labels, scores, test_df):\n",
    "    summary = []\n",
    "    zipped = zip(labels, scores, test_df[\"prompt\"])\n",
    "    res = sorted(zipped, key = lambda x: x[1], reverse=True)\n",
    "    for r in res:\n",
    "        summary.append(f\"Label: {r[0]}\\tScore: {r[1]}\\n{r[2]}\")\n",
    "    return summary\n",
    "\n",
    "def eval_df(test_df):\n",
    "    prompts = list(test_df[\"prompt\"])\n",
    "    res = openai.Completion.create(model=ft_model, prompt=prompts, temperature=0, max_tokens=1, logprobs=2)\n",
    "    labels = test_df[\"completion\"].map(lambda s: 1 if s == pos_label else 0)\n",
    "    scores = list(map(lambda r: get_score(r[\"logprobs\"][\"top_logprobs\"]), res[\"choices\"]))\n",
    "    texts = list(map(lambda r: r[\"text\"], res[\"choices\"]))\n",
    "    metrics = calculate_metrics(labels, scores, 0.5)\n",
    "    print(json.dumps(metrics,indent=4))\n",
    "    return create_summary(labels, scores, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fc55b",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f4dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-zmmRix6NzVPwQcNm3WF0v1A2\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "ft_model = 'ada:ft-safa:cm1-test-2023-03-29-23-31-09'\n",
    "test_dir_name = \"formatted\"\n",
    "test_file_name = \"test.jsonl\"\n",
    "data_dir = os.path.join(\"/Users/albertorodriguez/desktop/safa/datasets/openai\", test_dir_name)\n",
    "pos_label = \" yes###\"\n",
    "neg_label = \" no###\"\n",
    "\n",
    "test_path = os.path.join(data_dir, test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df42d8e",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc5ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191\n",
      " no###     618\n",
      " yes###    573\n",
      "Name: completion, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. The TG-PTC shall provide a mechanism for th...</td>\n",
       "      <td>no###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. The system shall allow user classes to be d...</td>\n",
       "      <td>yes###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Since the underlying communication pattern ...</td>\n",
       "      <td>yes###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. If there is a predictive brake warning cond...</td>\n",
       "      <td>yes###</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1. The system shall allow other VistA applicat...</td>\n",
       "      <td>no###</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt completion\n",
       "0  1. The TG-PTC shall provide a mechanism for th...      no###\n",
       "2  1. The system shall allow user classes to be d...     yes###\n",
       "3  1. Since the underlying communication pattern ...     yes###\n",
       "4  1. If there is a predictive brake warning cond...     yes###\n",
       "5  1. The system shall allow other VistA applicat...      no###"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(test_path, orient=\"records\", lines=True)\n",
    "test_df = test_df[test_df[\"prompt\"].map(lambda p: len(p) < 3000)]\n",
    "print(len(test_df))\n",
    "print(test_df[\"completion\"].value_counts())\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1a0a9",
   "metadata": {},
   "source": [
    "### All Positives and Undersampled Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46f4cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146\n",
      "{\n",
      "    \"sklearn\": {\n",
      "        \"ap\": 0.9484218085137677\n",
      "    },\n",
      "    \"tgen\": {\n",
      "        \"precision_at_recall_95\": 0.7830459770114943,\n",
      "        \"best_threshold\": 0.22108745269613916,\n",
      "        \"f1\": 0.8835978835978837,\n",
      "        \"f2\": 0.9130289903365544\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wx/rxzz6khs4w7bq1sthds7lr280000gn/T/ipykernel_25485/3501251284.py:39: FutureWarning: Metric is deprecated and will be removed in the next major version of datasets. Use the new library ðŸ¤— Evaluate instead: https://huggingface.co/docs/evaluate\n",
      "  f_metric = FMetric()\n"
     ]
    }
   ],
   "source": [
    "pos_df = test_df[test_df[\"completion\"] == pos_label]\n",
    "neg_df = test_df[test_df[\"completion\"] == neg_label]\n",
    "df = pd.concat([pos_df, neg_df.sample(n=len(pos_df))])\n",
    "print(len(df))\n",
    "summary_1 = eval_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e34fb",
   "metadata": {},
   "source": [
    "### Random Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69acb5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191\n",
      "{\n",
      "    \"sklearn\": {\n",
      "        \"ap\": 0.9466485285681704\n",
      "    },\n",
      "    \"tgen\": {\n",
      "        \"precision_at_recall_95\": 0.7752489331436699,\n",
      "        \"best_threshold\": 0.22133030946599005,\n",
      "        \"f1\": 0.8804920913884008,\n",
      "        \"f2\": 0.910904255319149\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# _, df_2 = train_test_split(test_df, test_size=200, stratify=test_df[\"completion\"])\n",
    "# print(len(df_2))\n",
    "print(len(test_df))\n",
    "summary_2 = eval_df(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073dd1de",
   "metadata": {},
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adefd162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\tScore: 0.9983657834574283\n",
      "1. The system shall integrate orders with progress notes, results, procedures, diagnosis, and Problem List.\n",
      "2. The system shall provide the ability to document a verbal order, including the clinician taking (receiving) the verbal order and the ordering physician in the patient record.\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "Label: 0\tScore: 0.9929402572067226\n",
      "1. The system shall include the ability to print prescriptions for signature and fax prescriptions to a local pharmacy with an electronic signature.\n",
      "2. The system shall provide the ability to specify prescription/medication order details including strength, route, frequency and comments. Strength, route and frequency must be captured and maintained as discrete data.\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "Label: 0\tScore: 0.9867629075576962\n",
      "1. The system shall require handwritten signatures for outpatient medication orders of schedule 2 and schedule 2n controlled substances due to DEA policy.\n",
      "2. The system shall provide the ability to utilize unique identifiers for Placer Order Number and unique identifiers for Filler Order Number for Lab results\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "Label: 0\tScore: 0.9820832528463401\n",
      "1. The system shall enforce these access levels when problems are entered via the encounter form. Problems entered on the encounter form by clerical personnel shall be left as UNVERIFIED.\n",
      "2. The system shall provide the ability to sign and co-sign charting entries as required.\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "Label: 0\tScore: 0.9699224239325113\n",
      "1. The system shall provide a way for user to quickly click on the specifications that he or she wants for each order placed.\n",
      "2. The system shall provide the ability to specify prescription/medication order details including strength, route, frequency and comments. Strength, route and frequency must be captured and maintained as discrete data.\n",
      "\n",
      "###\n",
      "\n",
      "\n",
      "Label: 0\tScore: 0.9516825254338719\n",
      "1. During a departure test, the OBU shall allow the train crew to repeat the Audible Alert test before providing acknowledgement that the test is passed.\n",
      "2. The TG-PTC shall visually and audibly display all exceptions to train handling rules.\n",
      "\n",
      "###\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "max_display = 5\n",
    "summary = summary_2\n",
    "for s in summary_1:\n",
    "    if i > max_display:\n",
    "        break\n",
    "    if \"Label: 0\" in s:\n",
    "        print(s)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59a035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
