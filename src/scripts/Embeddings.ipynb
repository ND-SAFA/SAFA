{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3410ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TGenLogger tgen (INFO)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from data.creators.trace_dataset_creator import TraceDatasetCreator\n",
    "from data.creators.multi_trace_dataset_creator import MultiTraceDatasetCreator\n",
    "from data.datasets.trace_dataset import TraceDataset\n",
    "from data.readers.hub_project_reader import HubProjectReader\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from util.logging.logger_manager import LoggerManager, logger\n",
    "from util.logging.logger_config import LoggerConfig\n",
    "\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "openai.organization = \"org-zmmRix6NzVPwQcNm3WF0v1A2\"\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "log_path = os.path.expanduser(\"~/desktop/safa/logs\")\n",
    "LoggerManager.configure_logger(LoggerConfig(output_dir=log_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae40ad",
   "metadata": {},
   "source": [
    "# Read Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b74e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from hub: https://safa-datasets-open.s3.amazonaws.com/datasets/open-source/cchit.zip\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/source.xml:118\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/target.xml:1066\n",
      "/Users/albertorodriguez/desktop/safa/datasets/HuggingFace/extracted/de7d81e78e8cd5bd1c84b62f339304a970f4f4819b0978cf3cbdfcf9c7748617/cchit/answer.txt:587\n",
      "Artifacts: 1180 Traces: 587 Queries: 1\n",
      "Number of orphan artifacts (693)\n",
      "No missing source artifacts. (0)\n",
      "No missing target artifacts. (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning artifacts...: 100%|███████████| 1180/1180 [00:00<00:00, 2059624.94it/s]\n",
      "Generating negative links between Requirements -> Regulatory Codes: 100%|█| 116/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Requirements: 116],[Regulatory Codes: 1064]\n",
      "Trace dataset(+587, -(122837) = 123424)\n",
      "123424\n"
     ]
    }
   ],
   "source": [
    "project_reader = HubProjectReader(\"cchit\")\n",
    "dataset_creator = TraceDatasetCreator(project_reader)\n",
    "dataset = dataset_creator.create()\n",
    "trace_df = dataset.to_dataframe()\n",
    "print(len(trace_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f9d9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_map(embeddings):\n",
    "    e_map = {}\n",
    "    for i, (a_id, a_row) in enumerate(dataset.artifact_df.iterrows()):\n",
    "        e_map[a_id] = embeddings[\"data\"][i][\"embedding\"]\n",
    "    return e_map\n",
    "\n",
    "def create_vsm_map(model):\n",
    "    e_map = {}\n",
    "    for i, (a_id, a_row) in enumerate(dataset.artifact_df.iterrows()):\n",
    "        e_map[a_id] = model.transform([a_row[\"content\"]]).toarray()[0]\n",
    "    return e_map\n",
    "\n",
    "def calculate_scores(e_map):\n",
    "    scores = []\n",
    "    for i, row in dataset.trace_df.iterrows():\n",
    "        source_id = row[\"source\"]\n",
    "        target_id = row[\"target\"]\n",
    "\n",
    "        link_score = cosine_similarity(e_map[source_id], e_map[target_id])\n",
    "        scores.append(link_score)\n",
    "    return scores\n",
    "\n",
    "def calculate_metrics(labels, scores, threshold):\n",
    "    from sklearn.metrics import average_precision_score\n",
    "    from sklearn.metrics import fbeta_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    from train.metrics.precision_at_recall_metric import PrecisionAtRecallMetric\n",
    "    from train.metrics.f1_metric import FMetric\n",
    "    \n",
    "    f_metric = FMetric()\n",
    "    p_at_r = PrecisionAtRecallMetric()\n",
    "    pred_labels = list(map(lambda s: 1 if s >= threshold else 0, scores))\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"sklearn\": {\n",
    "            \"threshold\": threshold,\n",
    "            \"precision\": precision_score(labels, pred_labels),\n",
    "            \"recall\": recall_score(labels, pred_labels),\n",
    "            \"f1\": fbeta_score(labels, pred_labels, beta=1),\n",
    "            \"f2\": fbeta_score(labels, pred_labels, beta=2),\n",
    "            \"ap\": average_precision_score(labels, scores),\n",
    "        },\n",
    "        \"tgen\": {\n",
    "            **p_at_r._compute(scores, labels),\n",
    "            **f_metric._compute(scores, labels)\n",
    "        }\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "339925ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_map = {}\n",
    "artifact_bodies = list(dataset.artifact_df[\"content\"])\n",
    "labels = list(dataset.trace_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9951b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_model.fit(artifact_bodies)\n",
    "\n",
    "vsm_map = create_vsm_map(tfidf_model)\n",
    "vsm_scores = calculate_scores(vsm_map)\n",
    "\n",
    "threshold = (max(vsm_scores) + min(vsm_scores)) / 2.0\n",
    "vsm_metrics = calculate_metrics(labels, vsm_scores, threshold)\n",
    "metric_map[\"vsm\"] = vsm_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4911ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"vsm\": {\n",
      "        \"sklearn\": {\n",
      "            \"threshold\": 0.28421813471297364,\n",
      "            \"precision\": 0.3063063063063063,\n",
      "            \"recall\": 0.05792163543441227,\n",
      "            \"f1\": 0.09742120343839543,\n",
      "            \"f2\": 0.06913379422529484,\n",
      "            \"ap\": 0.08488282102308545\n",
      "        },\n",
      "        \"tgen\": {\n",
      "            \"precision_at_recall_95\": 0.005636078985909803,\n",
      "            \"best_threshold\": 0.02044291460897167,\n",
      "            \"f1\": 0.16363636363636364,\n",
      "            \"f2\": 0.21614118580210193\n",
      "        }\n",
      "    },\n",
      "    \"text-embedding-ada-002\": {\n",
      "        \"sklearn\": {\n",
      "            \"threshold\": 0.8253527613877167,\n",
      "            \"precision\": 0.014154800507542647,\n",
      "            \"recall\": 0.8551959114139693,\n",
      "            \"f1\": 0.027848663042272268,\n",
      "            \"f2\": 0.06637928754661096,\n",
      "            \"ap\": 0.14888420952302583\n",
      "        },\n",
      "        \"tgen\": {\n",
      "            \"precision_at_recall_95\": 0.00854085990234644,\n",
      "            \"best_threshold\": 0.804586649179889,\n",
      "            \"f1\": 0.22376409366869038,\n",
      "            \"f2\": 0.25523717794365514\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = [\"text-embedding-ada-002\"]#,\n",
    "#           \"text-similarity-curie-001\", \n",
    "#           \"text-search-ada-doc-001\", # \"text-search-ada-query-001\"\n",
    "#           \"text-similarity-ada-001\",\n",
    "#           \"text-similarity-davinci-001\"]\n",
    "\n",
    "for model in models:\n",
    "    if model in metric_map:\n",
    "        continue\n",
    "    embeddings = openai.Embedding.create(input=artifact_bodies, model=model)\n",
    "\n",
    "    openai_map = create_map(embeddings)\n",
    "    openai_scores = calculate_scores(openai_map)\n",
    "\n",
    "    threshold = (max(openai_scores) + min(openai_scores)) / 2.0\n",
    "    metrics = calculate_metrics(labels, openai_scores, threshold)\n",
    "    metric_map[model] = metrics\n",
    "    \n",
    "print(json.dumps(metric_map, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.artifact_df.sample(n=1).iloc[0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb04c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
